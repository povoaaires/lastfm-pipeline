{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#  Create a spark session with Delta\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"SparkDelta\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "# Create spark context\n",
    "spark_delta = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark_delta.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos dados\n",
    "\n",
    "try:\n",
    "    df_top_tracks = spark_delta.read.option(\"multiline\", \"false\").json('c:/Users/benedito.aires/Documents/GitHub/lastfm-pipeline/data/in/getTopTracks.json')\n",
    "    df_top_artist = spark_delta.read.option(\"multiline\", \"false\").json('c:/Users/benedito.aires/Documents/GitHub/lastfm-pipeline/data/in/gettopartists.json')\n",
    "\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selecao = df_top_artist.select(\n",
    "    col('corpo.topartists.artist.name').cast('string').alias('name'),\n",
    "    col('corpo.topartists.artist.playcount').alias('playcount'),\n",
    "    col('corpo.topartists.artist.@attr.rank').alias('rank')\n",
    ")\n",
    "\n",
    "df_selecao_top_tracks = df_top_tracks.select(\n",
    "    col('corpo.recenttracks.track.artist.#text').cast('string').alias('artista'),\n",
    "    col('corpo.recenttracks.track.album.#text').alias('album'),\n",
    "    col('corpo.recenttracks.track.name').alias('musica'),\n",
    "    col('corpo.recenttracks.track.date.#text').alias('data_execucao')\n",
    "\n",
    "    \n",
    ").dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|             artista|               album|              musica|       data_execucao|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|[Edguy, DragonFor...|[Mandrake, Inhuma...|[All the Clowns, ...|[13 May 2023, 19:...|\n",
      "|[Fernando Mendes,...|[Selecao de Ouro,...|[Roda Gigante, Ro...|[28 Oct 2023, 16:...|\n",
      "|[Jemina Pearl, Je...|[Break It Up, Bre...|[No Good, Retrogr...|[12 Feb 2023, 03:...|\n",
      "|[The Cure, The Be...|[The Head on the ...|[Inbetween Days, ...|[29 Jan 2023, 18:...|\n",
      "|[Labrinth, Neon T...|[Ends & Begins, P...|[The Feels, Every...|[22 Sep 2023, 15:...|\n",
      "|[The Smiths, The ...|[Strangeways, Her...|[Unhappy Birthday...|[16 Aug 2023, 11:...|\n",
      "|[Marcelo Jeneci, ...|[Guaia, Umas e Ou...|[Aí Sim, Yolanda,...|[22 Apr 2024, 22:...|\n",
      "|[Whitesnake, Sona...|[Whitesnake (2018...|[Is This Love - 2...|[25 Jun 2023, 17:...|\n",
      "|[Chicago, Electri...|[Chicago 16 (Expa...|[Hard to Say I'm ...|[18 Sep 2023, 16:...|\n",
      "|[Dreamtale, Dream...|[Difference, Diff...|[Wings of Icaros,...|[08 Jul 2023, 16:...|\n",
      "|[McAuley Schenker...|[MSG, The Forgott...|[This Night Is Go...|[10 Mar 2023, 04:...|\n",
      "|[Stratovarius, D....|[Under Flaming Wi...|[Eagleheart - Liv...|[26 Jun 2023, 15:...|\n",
      "|[The Cure, The Be...|[Faith, A Hard Da...|[Faith, I Should ...|[29 Jan 2023, 19:...|\n",
      "|[ABBA, Skank, Caz...|[Super Trouper, O...|[The Winner Takes...|[07 Dec 2023, 15:...|\n",
      "|                NULL|                NULL|                NULL|                NULL|\n",
      "|[Elton John, Aero...|[Don't Shoot Me I...|[Skyline Pigeon -...|[18 Nov 2023, 15:...|\n",
      "|[H2O, Bon Jovi, S...|[F.T.T.W., Cross ...|[One Life, One Ch...|[17 Feb 2023, 12:...|\n",
      "|[Stratovarius, St...|[Dreamspace (Orig...|[We Are the Futur...|[23 Jan 2024, 15:...|\n",
      "|[Legião Urbana, D...|[Dois, Ária - Ao ...|[Eduardo e Mônica...|[08 Oct 2023, 23:...|\n",
      "|[Edguy, Mr. Big, ...|[Mandrake, Bump A...|[All the Clowns, ...|[02 Jul 2023, 13:...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_selecao_top_tracks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                name|           playcount|                rank|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[Stratovarius, Vo...|[2183, 999, 830, ...|[1, 2, 3, 4, 5, 6...|\n",
      "|[No Doubt, Beast ...|[60, 58, 57, 57, ...|[51, 52, 53, 54, ...|\n",
      "|[REO Speedwagon, ...|[38, 37, 37, 36, ...|[101, 102, 103, 1...|\n",
      "|[Kid Abelha, Raça...|[21, 21, 21, 21, ...|[151, 152, 153, 1...|\n",
      "|[Nilton Cesar, Ti...|[15, 15, 15, 14, ...|[201, 202, 203, 2...|\n",
      "|[R.E.M., Renato L...|[11, 11, 11, 11, ...|[251, 252, 253, 2...|\n",
      "|[Eminem, Forrozão...|[7, 7, 7, 7, 7, 7...|[301, 302, 303, 3...|\n",
      "|[Asleep at the Wh...|[5, 5, 5, 5, 5, 5...|[351, 352, 353, 3...|\n",
      "|[Damien Rice, Dea...|[4, 4, 4, 4, 4, 4...|[401, 402, 403, 4...|\n",
      "|[Avalanch, Baco E...|[3, 3, 3, 3, 3, 3...|[451, 452, 453, 4...|\n",
      "|[Matanza, Matogro...|[3, 3, 3, 3, 3, 3...|[501, 502, 503, 5...|\n",
      "|[Willie Nelson, Y...|[3, 3, 3, 3, 3, 3...|[551, 552, 553, 5...|\n",
      "|[Dimas e Seus Tec...|[2, 2, 2, 2, 2, 2...|[601, 602, 603, 6...|\n",
      "|[Johann Sebastian...|[2, 2, 2, 2, 2, 2...|[651, 652, 653, 6...|\n",
      "|[Queen, Rainbow, ...|[2, 2, 2, 2, 2, 2...|[701, 702, 703, 7...|\n",
      "|[Viper, Vk, White...|[2, 2, 2, 2, 2, 2...|[751, 752, 753, 7...|\n",
      "|[Axxis, B.J. Thom...|[1, 1, 1, 1, 1, 1...|[801, 802, 803, 8...|\n",
      "|[Bulutsuzluk Özle...|[1, 1, 1, 1, 1, 1...|[851, 852, 853, 8...|\n",
      "|[David Bowie, Dav...|[1, 1, 1, 1, 1, 1...|[901, 902, 903, 9...|\n",
      "|[Franz Ferdinand,...|[1, 1, 1, 1, 1, 1...|[951, 952, 953, 9...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_selecao.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_artistas = df_selecao.select(\n",
    "    posexplode(split(\"name\", \",\")).alias(\"pos_artista\", \"artista\"),\n",
    "    'playcount',\n",
    "    'rank'    \n",
    ").select(\n",
    "    'pos_artista',\n",
    "    'artista',\n",
    "    expr(\"playcount[pos_artista]\").cast('int').alias('playcount'),\n",
    "    expr(\"rank[pos_artista]\").cast('int').alias('rank')\n",
    "\n",
    ").drop('pos_artista')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_tracks_s = df_selecao_top_tracks.select(\n",
    "    posexplode(split(\"artista\", \",\")).alias(\"pos_artista\", \"artista\"),\n",
    "    'album',\n",
    "    'musica',\n",
    "    'data_execucao'    \n",
    ").select(\n",
    "    'pos_artista',\n",
    "    'artista',\n",
    "    expr(\"album[pos_artista]\").alias('album'),\n",
    "    expr(\"musica[pos_artista]\").alias('musica'),\n",
    "    expr(\"data_execucao[pos_artista]\").alias('data_execucao') \n",
    ").drop('pos_artista')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+----+\n",
      "|         artista|playcount|rank|\n",
      "+----------------+---------+----+\n",
      "|   [Stratovarius|     2183|   1|\n",
      "|         Volbeat|      999|   2|\n",
      "|           Keane|      830|   3|\n",
      "|       Dreamtale|      781|   4|\n",
      "|           Edguy|      507|   5|\n",
      "|  Blind Guardian|      388|   6|\n",
      "|       Green Day|      381|   7|\n",
      "|       Helloween|      370|   8|\n",
      "| Shakin' Stevens|      331|   9|\n",
      "|        The Cure|      324|  10|\n",
      "|      The Smiths|      317|  11|\n",
      "|         Sabaton|      231|  12|\n",
      "|  Sonata Arctica|      213|  13|\n",
      "|       Nightwish|      196|  14|\n",
      "|      Whitesnake|      196|  15|\n",
      "|          Travis|      195|  16|\n",
      "|     DragonForce|      180|  17|\n",
      "|     The Beatles|      167|  18|\n",
      "|    Los Hermanos|      161|  19|\n",
      "|      Maria Gadú|      161|  20|\n",
      "+----------------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_top_artistas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------------------+\n",
      "|             artista|               album|              musica|     data_execucao|\n",
      "+--------------------+--------------------+--------------------+------------------+\n",
      "|              [Edguy|            Mandrake|      All the Clowns|13 May 2023, 19:45|\n",
      "|         DragonForce|     Inhuman Rampage|Through the Fire ...|13 May 2023, 19:35|\n",
      "|             Sabaton|Coat Of Arms (Bon...|  The Final Solution|13 May 2023, 19:32|\n",
      "|             Sabaton|              Heroes|    To Hell and Back|13 May 2023, 19:28|\n",
      "|             Sabaton|           Metalizer|The Hammer Has Fa...|13 May 2023, 19:20|\n",
      "|             Ednardo|O Romance Do Pavã...|    Pavão Mysteriozo|13 May 2023, 17:49|\n",
      "|     O Teatro Mágico|Entrada para Raro...|   O anjo mais velho|13 May 2023, 17:44|\n",
      "|           Fábio Jr.|Fábio Jr. 2002 (A...|    20 e Poucos Anos|13 May 2023, 17:41|\n",
      "|    Flavio Venturini|Bis - Flavio Vent...|           Espanhola|13 May 2023, 17:38|\n",
      "|              Fagner|  Romance No Deserto|            Deslizes|13 May 2023, 17:33|\n",
      "|          The Smiths|Strangeways, Here...|Girlfriend in a C...|13 May 2023, 17:31|\n",
      "|        Los Hermanos|        Los Hermanos|               Aline|13 May 2023, 17:29|\n",
      "|            Bon Jovi|               Crush|        It's My Life|13 May 2023, 17:25|\n",
      "|        Stratovarius|Destiny (Reissue ...|4000 Rainy Nights...|13 May 2023, 17:19|\n",
      "|             Mr. Big|Bump Ahead [Expan...|Wild World - 2009...|13 May 2023, 17:16|\n",
      "|  Bayern-Fans United|Stern des Südens ...|Stern des Südens ...|13 May 2023, 17:12|\n",
      "| FC Bayern and An...|Jetzt geht's wied...|FC Bayern - forev...|13 May 2023, 17:08|\n",
      "|           Pearl Jam|           Last Kiss|           Last Kiss|13 May 2023, 17:02|\n",
      "|     Velvet Revolver|            Libertad|      The Last Fight|13 May 2023, 16:55|\n",
      "|           Green Day|              Nimrod|Good Riddance (Ti...|12 May 2023, 21:57|\n",
      "+--------------------+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_top_tracks_s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while calling o224.save.\n",
      ": com.google.common.util.concurrent.ExecutionError: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n",
      "\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2261)\n",
      "\tat com.google.common.cache.LocalCache.get(LocalCache.java:4000)\n",
      "\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4789)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog$.getDeltaLogFromCache$1(DeltaLog.scala:790)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog$.apply(DeltaLog.scala:800)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog$.forTable(DeltaLog.scala:677)\n",
      "\tat org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:189)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:304)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
      "\tat java.lang.reflect.Method.invoke(Unknown Source)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Unknown Source)\n",
      "Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)\n",
      "\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249)\n",
      "\tat org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454)\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)\n",
      "\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\n",
      "\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\n",
      "\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)\n",
      "\tat io.delta.storage.HadoopFileSystemLogStore.listFrom(HadoopFileSystemLogStore.java:59)\n",
      "\tat org.apache.spark.sql.delta.storage.LogStoreAdaptor.listFrom(LogStore.scala:452)\n",
      "\tat org.apache.spark.sql.delta.storage.DelegatingLogStore.listFrom(DelegatingLogStore.scala:127)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.listFrom(SnapshotManagement.scala:94)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.listFrom$(SnapshotManagement.scala:93)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog.listFrom(DeltaLog.scala:72)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.listFromOrNone(SnapshotManagement.scala:111)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.listFromOrNone$(SnapshotManagement.scala:107)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog.listFromOrNone(DeltaLog.scala:72)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$listDeltaCompactedDeltaAndCheckpointFiles$1(SnapshotManagement.scala:132)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog.recordFrameProfile(DeltaLog.scala:72)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:133)\n",
      "\tat com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)\n",
      "\tat com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog.recordOperation(DeltaLog.scala:72)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:132)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:122)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:112)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog.recordDeltaOperation(DeltaLog.scala:72)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.listDeltaCompactedDeltaAndCheckpointFiles(SnapshotManagement.scala:132)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.listDeltaCompactedDeltaAndCheckpointFiles$(SnapshotManagement.scala:127)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog.listDeltaCompactedDeltaAndCheckpointFiles(DeltaLog.scala:72)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.getLogSegmentForVersion(SnapshotManagement.scala:178)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.getLogSegmentForVersion$(SnapshotManagement.scala:165)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog.getLogSegmentForVersion(DeltaLog.scala:72)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.getLogSegmentFrom(SnapshotManagement.scala:88)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.getLogSegmentFrom$(SnapshotManagement.scala:84)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog.getLogSegmentFrom(DeltaLog.scala:72)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotAtInit$1(SnapshotManagement.scala:438)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog.recordFrameProfile(DeltaLog.scala:72)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit(SnapshotManagement.scala:434)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit$(SnapshotManagement.scala:433)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog.getSnapshotAtInit(DeltaLog.scala:72)\n",
      "\tat org.apache.spark.sql.delta.SnapshotManagement.$init$(SnapshotManagement.scala:60)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog.<init>(DeltaLog.scala:78)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$4(DeltaLog.scala:779)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$3(DeltaLog.scala:774)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog$.recordFrameProfile(DeltaLog.scala:598)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:133)\n",
      "\tat com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)\n",
      "\tat com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog$.recordOperation(DeltaLog.scala:598)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:132)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:122)\n",
      "\tat org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:112)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog$.recordDeltaOperation(DeltaLog.scala:598)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog$.createDeltaLog$1(DeltaLog.scala:773)\n",
      "\tat org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$5(DeltaLog.scala:791)\n",
      "\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4792)\n",
      "\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)\n",
      "\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)\n",
      "\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)\n",
      "\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2257)\n",
      "\t... 47 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_top_artistas.write.format(\"delta\").mode(\"overwrite\").save('c:/Users/benedito.aires/Documents/GitHub/lastfm-pipeline/data/out/top_artists/')\n",
    "\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_top_tracks_s.write.format('delta').mode('overwrite','true').save('c:/Users/benedito.aires/Documents/GitHub/lastfm-pipeline/data/out/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
